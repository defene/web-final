# RAG System Configuration

# Model Settings
models:
  # OpenAI API Models
  openai:
    api_key: ${OPENAI_API_KEY}  # Set in .env file
    chat_model: "gpt-4o-mini"
    embedding_model: "text-embedding-3-small"
    
  # Local HuggingFace Models
  local:
    # LLM options: meta-llama/Llama-3.2-1B-Instruct, mistralai/Mistral-7B-Instruct-v0.3, google/flan-t5-large
    llm_model: "google/flan-t5-large"
    # Embedding options: BAAI/bge-base-en-v1.5, sentence-transformers/all-MiniLM-L6-v2, facebook/contriever
    embedding_model: "BAAI/bge-base-en-v1.5"
    # Reranker model
    reranker_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
    device: "cuda"  # cuda or cpu
    
  # Active model source: "openai" or "local"
  active_source: "local"

# Retrieval Settings
retrieval:
  # Sparse retrieval (BM25)
  sparse:
    enabled: true
    k1: 1.5
    b: 0.75
    
  # Dense retrieval
  dense:
    enabled: true
    index_type: "faiss"  # faiss or chromadb
    similarity_metric: "cosine"  # cosine, l2, ip
    
  # Hybrid retrieval
  hybrid:
    enabled: false
    fusion_method: "rrf"  # rrf (Reciprocal Rank Fusion) or weighted
    rrf_k: 60
    weights:
      sparse: 0.3
      dense: 0.7
      
  # Common settings
  top_k: 5
  chunk_size: 512
  chunk_overlap: 50

# Reranking Settings
reranking:
  enabled: false
  top_k: 3  # Number of documents after reranking

# RAG Pipeline Settings
rag:
  # Pipeline type: "baseline", "hybrid", "rerank", "iterative"
  pipeline_type: "baseline"
  
  # Iterative RAG settings
  iterative:
    max_iterations: 2
    confidence_threshold: 0.7
    
  # Adaptive top-k settings
  adaptive_k:
    enabled: false
    min_k: 3
    max_k: 10
    
  # Prompt templates
  prompts:
    qa_template: |
      Answer the question based on the following context. If the answer cannot be found in the context, say "I don't know."
      
      Context:
      {context}
      
      Question: {question}
      
      Answer:

# Data Settings
data:
  # Dataset options: "nq", "hotpotqa", "bright", "custom"
  dataset: "nq"
  
  # Paths
  raw_dir: "data/raw"
  processed_dir: "data/processed"
  index_dir: "data/indices"
  
  # Processing
  max_documents: null  # null for all documents
  test_size: 0.1

# Evaluation Settings
evaluation:
  # Retrieval metrics
  retrieval:
    metrics: ["mrr", "precision@1", "precision@3", "precision@5", "recall@5", "recall@10"]
    
  # RAG metrics (using Ragas)
  rag:
    metrics: ["faithfulness", "answer_relevancy", "context_precision", "context_recall"]
    
  # QA metrics
  qa:
    metrics: ["exact_match", "f1"]

# Logging Settings
logging:
  level: "INFO"
  save_results: true
  results_dir: "results"


